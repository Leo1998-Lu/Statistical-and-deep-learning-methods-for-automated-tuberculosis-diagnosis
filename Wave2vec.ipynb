{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4523931,"sourceType":"datasetVersion","datasetId":2643744},{"sourceId":4523947,"sourceType":"datasetVersion","datasetId":2643754}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\nimport torch\nimport torchaudio\nimport torchvision\nimport numpy as np\nfrom torchvision import models\nimport torchaudio\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport timm\nimport gc\nimport librosa","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:27.154669Z","iopub.execute_input":"2023-11-30T21:58:27.155136Z","iopub.status.idle":"2023-11-30T21:58:31.673254Z","shell.execute_reply.started":"2023-11-30T21:58:27.155097Z","shell.execute_reply":"2023-11-30T21:58:31.672342Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tabular = True","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:31.675016Z","iopub.execute_input":"2023-11-30T21:58:31.675780Z","iopub.status.idle":"2023-11-30T21:58:31.681846Z","shell.execute_reply.started":"2023-11-30T21:58:31.675736Z","shell.execute_reply":"2023-11-30T21:58:31.681003Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('/kaggle/input/tb-coughs-audio/data')\nsolicited = data_dir/'solicited'\nTRAIN_FOLDER = solicited\ncv_train = False # cross-validation or one fold","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:31.683156Z","iopub.execute_input":"2023-11-30T21:58:31.683488Z","iopub.status.idle":"2023-11-30T21:58:31.691029Z","shell.execute_reply.started":"2023-11-30T21:58:31.683459Z","shell.execute_reply":"2023-11-30T21:58:31.690211Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"MODEL_FOLDER = Path('./models')\n\nos.makedirs(MODEL_FOLDER, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:31.692826Z","iopub.execute_input":"2023-11-30T21:58:31.693139Z","iopub.status.idle":"2023-11-30T21:58:31.701079Z","shell.execute_reply.started":"2023-11-30T21:58:31.693113Z","shell.execute_reply":"2023-11-30T21:58:31.700313Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport torchaudio\n\ndata_dir = Path('/kaggle/input/tb-tab-data')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:31.702083Z","iopub.execute_input":"2023-11-30T21:58:31.702332Z","iopub.status.idle":"2023-11-30T21:58:32.183497Z","shell.execute_reply.started":"2023-11-30T21:58:31.702309Z","shell.execute_reply":"2023-11-30T21:58:32.182293Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_sample_length(fn,base_path):\n    p = base_path/fn\n    x, sr = torchaudio.load(str(p))\n    return x.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.185020Z","iopub.execute_input":"2023-11-30T21:58:32.185411Z","iopub.status.idle":"2023-11-30T21:58:32.191205Z","shell.execute_reply.started":"2023-11-30T21:58:32.185372Z","shell.execute_reply":"2023-11-30T21:58:32.190206Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def find_path(filename,directory_path=data_dir):\n    l = list(directory_path.glob(\"**/\" + filename))\n    if len(l) == 0:\n        return None\n    elif len(l) == 1:\n        return l[0]\n    else:\n        return l","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.192355Z","iopub.execute_input":"2023-11-30T21:58:32.192627Z","iopub.status.idle":"2023-11-30T21:58:32.201759Z","shell.execute_reply.started":"2023-11-30T21:58:32.192603Z","shell.execute_reply":"2023-11-30T21:58:32.200908Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"solicited_df = pd.read_csv(find_path('CODA_TB_Solicited_Meta_Info.csv'))\nclinical_df = pd.read_csv(find_path('CODA_TB_Clinical_Meta_Info.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.203036Z","iopub.execute_input":"2023-11-30T21:58:32.203368Z","iopub.status.idle":"2023-11-30T21:58:32.254282Z","shell.execute_reply.started":"2023-11-30T21:58:32.203338Z","shell.execute_reply":"2023-11-30T21:58:32.253314Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#add tb_status\ndf = pd.merge(solicited_df, clinical_df[['participant', 'tb_status']], on = 'participant', how = 'inner')\n# reset index so that .loc and .iloc are same for index\ndf.reset_index(drop=True,inplace=True)\n#add orig_id\ndf['orig_id'] = df.index\n\nn_folds = 5\nseed = 2023\n\n\n\nskf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=seed)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df, df['tb_status'], groups = df[\"participant\"])):\n    df.loc[val_idx, 'fold'] = fold\n    \ndisplay(df.groupby(['fold','tb_status'])['filename'].count())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.255645Z","iopub.execute_input":"2023-11-30T21:58:32.256426Z","iopub.status.idle":"2023-11-30T21:58:32.778417Z","shell.execute_reply.started":"2023-11-30T21:58:32.256389Z","shell.execute_reply":"2023-11-30T21:58:32.777437Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"fold  tb_status\n0.0   0            1343\n      1             548\n1.0   0            1392\n      1             517\n2.0   0            1352\n      1             684\n3.0   0            1378\n      1             621\n4.0   0            1377\n      1             560\nName: filename, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv(\"metadata.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.782922Z","iopub.execute_input":"2023-11-30T21:58:32.783277Z","iopub.status.idle":"2023-11-30T21:58:32.865782Z","shell.execute_reply.started":"2023-11-30T21:58:32.783245Z","shell.execute_reply":"2023-11-30T21:58:32.864922Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"\n## Load the metadata","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"metadata.csv\",index_col=[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.867152Z","iopub.execute_input":"2023-11-30T21:58:32.867750Z","iopub.status.idle":"2023-11-30T21:58:32.892234Z","shell.execute_reply.started":"2023-11-30T21:58:32.867715Z","shell.execute_reply":"2023-11-30T21:58:32.891419Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df['path'] = \"/kaggle/input/tb-coughs-audio/data/solicited/\" + df['filename']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.893252Z","iopub.execute_input":"2023-11-30T21:58:32.893524Z","iopub.status.idle":"2023-11-30T21:58:32.899381Z","shell.execute_reply.started":"2023-11-30T21:58:32.893500Z","shell.execute_reply":"2023-11-30T21:58:32.898378Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.900456Z","iopub.execute_input":"2023-11-30T21:58:32.900706Z","iopub.status.idle":"2023-11-30T21:58:32.925181Z","shell.execute_reply.started":"2023-11-30T21:58:32.900683Z","shell.execute_reply":"2023-11-30T21:58:32.924288Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       participant                       filename  sound_prediction_score  \\\n0     CODA_TB_0001  1645088710003-recording-1.wav                0.990254   \n1     CODA_TB_0001  1645088760390-recording-1.wav                0.990272   \n2     CODA_TB_0001  1645088760830-recording-1.wav                0.990112   \n3     CODA_TB_0001  1645088710843-recording-1.wav                0.990152   \n4     CODA_TB_0001  1645088759950-recording-1.wav                0.990039   \n...            ...                            ...                     ...   \n9767  CODA_TB_1107  1658214018804-recording-1.wav                0.941761   \n9768  CODA_TB_1107  1658213992939-recording-1.wav                0.904569   \n9769  CODA_TB_1107  1658213992139-recording-1.wav                0.934713   \n9770  CODA_TB_1107  1658213940569-recording-1.wav                0.912813   \n9771  CODA_TB_1107  1658213974948-recording-1.wav                0.939352   \n\n      tb_status  orig_id  fold  \\\n0             0        0   2.0   \n1             0        1   2.0   \n2             0        2   2.0   \n3             0        3   2.0   \n4             0        4   2.0   \n...         ...      ...   ...   \n9767          0     9767   0.0   \n9768          0     9768   0.0   \n9769          0     9769   0.0   \n9770          0     9770   0.0   \n9771          0     9771   0.0   \n\n                                                   path  \n0     /kaggle/input/tb-coughs-audio/data/solicited/1...  \n1     /kaggle/input/tb-coughs-audio/data/solicited/1...  \n2     /kaggle/input/tb-coughs-audio/data/solicited/1...  \n3     /kaggle/input/tb-coughs-audio/data/solicited/1...  \n4     /kaggle/input/tb-coughs-audio/data/solicited/1...  \n...                                                 ...  \n9767  /kaggle/input/tb-coughs-audio/data/solicited/1...  \n9768  /kaggle/input/tb-coughs-audio/data/solicited/1...  \n9769  /kaggle/input/tb-coughs-audio/data/solicited/1...  \n9770  /kaggle/input/tb-coughs-audio/data/solicited/1...  \n9771  /kaggle/input/tb-coughs-audio/data/solicited/1...  \n\n[9772 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant</th>\n      <th>filename</th>\n      <th>sound_prediction_score</th>\n      <th>tb_status</th>\n      <th>orig_id</th>\n      <th>fold</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CODA_TB_0001</td>\n      <td>1645088710003-recording-1.wav</td>\n      <td>0.990254</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CODA_TB_0001</td>\n      <td>1645088760390-recording-1.wav</td>\n      <td>0.990272</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CODA_TB_0001</td>\n      <td>1645088760830-recording-1.wav</td>\n      <td>0.990112</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CODA_TB_0001</td>\n      <td>1645088710843-recording-1.wav</td>\n      <td>0.990152</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CODA_TB_0001</td>\n      <td>1645088759950-recording-1.wav</td>\n      <td>0.990039</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9767</th>\n      <td>CODA_TB_1107</td>\n      <td>1658214018804-recording-1.wav</td>\n      <td>0.941761</td>\n      <td>0</td>\n      <td>9767</td>\n      <td>0.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>9768</th>\n      <td>CODA_TB_1107</td>\n      <td>1658213992939-recording-1.wav</td>\n      <td>0.904569</td>\n      <td>0</td>\n      <td>9768</td>\n      <td>0.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>9769</th>\n      <td>CODA_TB_1107</td>\n      <td>1658213992139-recording-1.wav</td>\n      <td>0.934713</td>\n      <td>0</td>\n      <td>9769</td>\n      <td>0.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>9770</th>\n      <td>CODA_TB_1107</td>\n      <td>1658213940569-recording-1.wav</td>\n      <td>0.912813</td>\n      <td>0</td>\n      <td>9770</td>\n      <td>0.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n    <tr>\n      <th>9771</th>\n      <td>CODA_TB_1107</td>\n      <td>1658213974948-recording-1.wav</td>\n      <td>0.939352</td>\n      <td>0</td>\n      <td>9771</td>\n      <td>0.0</td>\n      <td>/kaggle/input/tb-coughs-audio/data/solicited/1...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9772 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nfrom datasets import Audio\nfrom datasets import Dataset\n\nfrom datasets import concatenate_datasets\n\ntrain_paths = df['path'][df['fold']!=1]\nval_paths = df['path'][df['fold']==1]\n\n\ntrain_ds = Dataset.from_dict({\"audio\":train_paths ,\"label\":df['tb_status'][df['fold']!=1]}).cast_column(\"audio\", Audio(sampling_rate=22050))\nval_ds = Dataset.from_dict({\"audio\":val_paths ,\"label\":df['tb_status'][df['fold']==1]}).cast_column(\"audio\", Audio(sampling_rate=22050))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:32.926320Z","iopub.execute_input":"2023-11-30T21:58:32.928634Z","iopub.status.idle":"2023-11-30T21:58:33.547188Z","shell.execute_reply.started":"2023-11-30T21:58:32.928607Z","shell.execute_reply":"2023-11-30T21:58:33.546428Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:33.548212Z","iopub.execute_input":"2023-11-30T21:58:33.548649Z","iopub.status.idle":"2023-11-30T21:58:33.554381Z","shell.execute_reply.started":"2023-11-30T21:58:33.548622Z","shell.execute_reply":"2023-11-30T21:58:33.553446Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['audio', 'label'],\n    num_rows: 7863\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoFeatureExtractor\n\nfeature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-large\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:33.555399Z","iopub.execute_input":"2023-11-30T21:58:33.555674Z","iopub.status.idle":"2023-11-30T21:58:36.137767Z","shell.execute_reply.started":"2023-11-30T21:58:33.555644Z","shell.execute_reply":"2023-11-30T21:58:36.136950Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0c84ae3f42482da37899df7824b54e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b2d0564b7964c2db05b25194df4db0e"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n    inputs = feature_extractor(\n        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=22050, truncation=True\n    )\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:36.138824Z","iopub.execute_input":"2023-11-30T21:58:36.139517Z","iopub.status.idle":"2023-11-30T21:58:36.145018Z","shell.execute_reply.started":"2023-11-30T21:58:36.139488Z","shell.execute_reply":"2023-11-30T21:58:36.143966Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_encoded_ds = train_ds.map(preprocess_function, remove_columns=\"audio\", batched=True)\nval_encoded_ds = val_ds.map(preprocess_function, remove_columns=\"audio\", batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:58:36.146149Z","iopub.execute_input":"2023-11-30T21:58:36.146410Z","iopub.status.idle":"2023-11-30T21:59:37.161168Z","shell.execute_reply.started":"2023-11-30T21:58:36.146387Z","shell.execute_reply":"2023-11-30T21:59:37.160155Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16f015c43a44c318f5f16583dd00e83"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d53a6957b2340dfb0fe466185bd0b67"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:59:37.162467Z","iopub.execute_input":"2023-11-30T21:59:37.163652Z","iopub.status.idle":"2023-11-30T21:59:49.692482Z","shell.execute_reply.started":"2023-11-30T21:59:37.163613Z","shell.execute_reply":"2023-11-30T21:59:49.691456Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nfrom sklearn.metrics import roc_curve,roc_auc_score,accuracy_score, f1_score, log_loss, precision_score, recall_score\n\nroc_auc = evaluate.load(\"roc_auc\")\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    \n    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n\ndef compute_metrics(eval_pred):\n    preds = eval_pred.predictions[:, 1] \n    labels = eval_pred.label_ids\n    roc_auc = roc_auc_score(labels, preds)\n    return {\"AUROC\": roc_auc}","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:59:49.694196Z","iopub.execute_input":"2023-11-30T21:59:49.694561Z","iopub.status.idle":"2023-11-30T21:59:53.177975Z","shell.execute_reply.started":"2023-11-30T21:59:49.694525Z","shell.execute_reply":"2023-11-30T21:59:53.177115Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a57bca2d0114cd3bba0f8c1b07ec15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24bd6d5196bf4a0c9e27ba2f210fe1cc"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForAudioClassification.from_pretrained(\"facebook/wav2vec2-large\", num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T21:59:53.180506Z","iopub.execute_input":"2023-11-30T21:59:53.180797Z","iopub.status.idle":"2023-11-30T22:00:02.712437Z","shell.execute_reply.started":"2023-11-30T21:59:53.180770Z","shell.execute_reply":"2023-11-30T22:00:02.711569Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76b0e210aef042158605f92928cc6299"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-large were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.codevectors', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.weight_proj.bias', 'project_hid.bias', 'project_q.weight', 'project_q.bias']\n- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large and are newly initialized: ['classifier.weight', 'projector.weight', 'classifier.bias', 'projector.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"wave2vec_tb\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=64,\n    gradient_accumulation_steps=1,\n    per_device_eval_batch_size=64,\n    num_train_epochs=10,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n#     metric_for_best_model='roc_auc',\n    save_total_limit=1,\n    # fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_encoded_ds,\n    eval_dataset=val_encoded_ds,\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:00:48.558658Z","iopub.execute_input":"2023-11-30T22:00:48.559329Z","iopub.status.idle":"2023-11-30T22:32:37.264829Z","shell.execute_reply.started":"2023-11-30T22:00:48.559284Z","shell.execute_reply":"2023-11-30T22:32:37.263945Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1230' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1230/1230 31:46, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Auroc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.596500</td>\n      <td>0.586242</td>\n      <td>0.629654</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.577600</td>\n      <td>0.557612</td>\n      <td>0.633022</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.565700</td>\n      <td>0.545635</td>\n      <td>0.679669</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.521600</td>\n      <td>0.569156</td>\n      <td>0.676242</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.483300</td>\n      <td>0.579090</td>\n      <td>0.670216</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.523800</td>\n      <td>0.560839</td>\n      <td>0.690779</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.518100</td>\n      <td>0.571556</td>\n      <td>0.689750</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.468500</td>\n      <td>0.575052</td>\n      <td>0.690791</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.487700</td>\n      <td>0.592846</td>\n      <td>0.675115</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.475900</td>\n      <td>0.594624</td>\n      <td>0.678255</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1230, training_loss=0.5261216462143068, metrics={'train_runtime': 1898.077, 'train_samples_per_second': 41.426, 'train_steps_per_second': 0.648, 'total_flos': 1.6420318297247974e+18, 'train_loss': 0.5261216462143068, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"val_encoded_ds","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:43:14.142659Z","iopub.execute_input":"2023-11-30T22:43:14.143476Z","iopub.status.idle":"2023-11-30T22:43:14.149337Z","shell.execute_reply.started":"2023-11-30T22:43:14.143441Z","shell.execute_reply":"2023-11-30T22:43:14.148386Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['label', 'input_values'],\n    num_rows: 1909\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_paths","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:45:03.891779Z","iopub.execute_input":"2023-11-30T22:45:03.892675Z","iopub.status.idle":"2023-11-30T22:45:03.901966Z","shell.execute_reply.started":"2023-11-30T22:45:03.892642Z","shell.execute_reply":"2023-11-30T22:45:03.899754Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"18      /kaggle/input/tb-coughs-audio/data/solicited/1...\n19      /kaggle/input/tb-coughs-audio/data/solicited/1...\n20      /kaggle/input/tb-coughs-audio/data/solicited/1...\n21      /kaggle/input/tb-coughs-audio/data/solicited/1...\n22      /kaggle/input/tb-coughs-audio/data/solicited/1...\n                              ...                        \n9703    /kaggle/input/tb-coughs-audio/data/solicited/1...\n9704    /kaggle/input/tb-coughs-audio/data/solicited/1...\n9705    /kaggle/input/tb-coughs-audio/data/solicited/1...\n9706    /kaggle/input/tb-coughs-audio/data/solicited/1...\n9707    /kaggle/input/tb-coughs-audio/data/solicited/1...\nName: path, Length: 1909, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\nclassifier = pipeline(\"audio-classification\", model=\"/kaggle/working/wave2vec_tb/checkpoint-369\")\nval_pred = []\nfor x in tqdm(val_paths):\n    val_pred.append(classifier(x)[1]['score'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:49:12.718770Z","iopub.execute_input":"2023-11-30T22:49:12.719267Z","iopub.status.idle":"2023-11-30T23:00:57.904240Z","shell.execute_reply.started":"2023-11-30T22:49:12.719229Z","shell.execute_reply":"2023-11-30T23:00:57.903263Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"100%|██████████| 1909/1909 [11:41<00:00,  2.72it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"thr = [0.5,0.2,0.4]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:03:22.986843Z","iopub.execute_input":"2023-11-30T23:03:22.987253Z","iopub.status.idle":"2023-11-30T23:03:22.992118Z","shell.execute_reply.started":"2023-11-30T23:03:22.987222Z","shell.execute_reply":"2023-11-30T23:03:22.990927Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print('accuracy_scores:',(accuracy_score(df['tb_status'][df['fold']==1], [1 if x >thr[0] else 0 for x in val_pred])))\nprint('sensitivity_scores:',(recall_score(df['tb_status'][df['fold']==1], [1 if x >thr[1] else 0 for x in val_pred])))\nprint('specificity_scores',(precision_score(df['tb_status'][df['fold']==1], [1 if x >thr[2] else 0 for x in val_pred])))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:03:24.549177Z","iopub.execute_input":"2023-11-30T23:03:24.549639Z","iopub.status.idle":"2023-11-30T23:03:24.570592Z","shell.execute_reply.started":"2023-11-30T23:03:24.549598Z","shell.execute_reply":"2023-11-30T23:03:24.569773Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"accuracy_scores: 0.7291775798847564\nsensitivity_scores: 0.8085106382978723\nspecificity_scores 0.3892709766162311\n","output_type":"stream"}]}]}